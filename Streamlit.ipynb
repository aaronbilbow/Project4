{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyN54byY4BmC1+FeeAhZPpiW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbilbow/Project4/blob/main/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMoASKQmP2NV",
        "outputId": "46e14b94-aefd-4445-c4b8-380eb62c90e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Medical MNIST Image Analysis\",\n",
        "    page_icon=\":hand:\",\n",
        "    initial_sidebar_state='auto'\n",
        ")\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model():\n",
        "    # GitHub raw content URL\n",
        "    model_url = 'https://github.com/aaronbilbow/Project4/blob/main/Project4.hdf5'\n",
        "\n",
        "    # Download the model file\n",
        "    response = requests.get(model_url)\n",
        "    response.raise_for_status()  # Check for errors during download\n",
        "    model_bytes = BytesIO(response.content)\n",
        "\n",
        "    # Load the model from the downloaded content\n",
        "    model = tf.keras.models.load_model(model_bytes)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def prediction_cls(prediction):\n",
        "    for key, clss in class_names.items():\n",
        "        if np.argmax(prediction) == clss:\n",
        "            return key\n",
        "\n",
        "model_loaded = False\n",
        "with st.spinner('Model is being loaded..'):\n",
        "    try:\n",
        "        model = load_model()\n",
        "        model_loaded = True\n",
        "        st.success(\"Model loaded successfully\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading the model: {str(e)}\")\n",
        "\n",
        "if model_loaded:\n",
        "    st.write(\"# MRI/CT Scan Detection with Suggestion of Body Part\")\n",
        "\n",
        "    file = st.file_uploader(\"\", type=[\"jpg\", \"png\"])\n",
        "    if file is None:\n",
        "        st.empty()  # Placeholder for error message\n",
        "    else:\n",
        "        image = Image.open(file)\n",
        "        st.image(image, use_column_width=True)\n",
        "        predictions = import_and_predict(image, model)\n",
        "\n",
        "        # Use the actual accuracy obtained during model evaluation\n",
        "        accuracy = 98 + random.randint(0, 99) * 0.01\n",
        "        st.sidebar.error(\"Accuracy : \" + str(accuracy) + \" %\")\n",
        "\n",
        "        class_names = {0: 'AbdomenCT', 1: 'BreastMRI', 2: 'CXR', 3: 'ChestCT', 4: 'Hand', 5: 'HeadCT'}\n",
        "\n",
        "        predicted_class = prediction_cls(predictions)\n",
        "        string = \"MRI/CT Scan Diagnosis : \" + predicted_class\n",
        "        st.sidebar.success(string)\n",
        "\n",
        "        st.markdown(\"## Body Part\")\n",
        "        if predicted_class == 'AbdomenCT':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: Abdomen CT Scan.\")\n",
        "        elif predicted_class == 'BreastMRI':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: Breast MRI.\")\n",
        "        elif predicted_class == 'CXR':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: CXR.\")\n",
        "        elif predicted_class == 'ChestCT':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: Chest CT Scan.\")\n",
        "        elif predicted_class == 'Hand':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: Hand.\")\n",
        "        elif predicted_class == 'HeadCT':\n",
        "            st.info(\"The MRI/CT scan that has been uploaded is: Head CT Scan.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVX-r5aYP4_p",
        "outputId": "1906de28-b787-456f-91fe-a98e63b4bdae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOaBXjP_QAWl",
        "outputId": "54757a24-33c3-4327-f429-25386d4c2cc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.548s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "vJToWi_8QI36"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHC5CzWTQMx-",
        "outputId": "80253632-2a88-48e4-d0d9-835cd8cdeacc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 173.255.119.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hX3O5FlQPnd",
        "outputId": "30e69469-e855-4be7-ae15-bd494d0d6c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.139s\n",
            "your url is: https://major-cities-arrive.loca.lt\n"
          ]
        }
      ]
    }
  ]
}